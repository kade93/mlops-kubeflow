{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381a0895-3cfd-4d89-b470-831fcd6a0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow import fairing\n",
    "\n",
    "DOCKER_REGISTRY = 'www.dolearn.io:30003/kade-kubeflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29afef1a-9e46-4475-9272-be0758b94396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_fairing():\n",
    "    \n",
    "    import numpy as np\n",
    "#     import matplotlib.pyplot as plt\n",
    "    import datetime, os\n",
    "\n",
    "    import torch\n",
    "    from torchvision import transforms, datasets\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "    from torch import nn\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    \n",
    "    train_data = datasets.FashionMNIST(\n",
    "    root=\"/home/jovyan/mlops-kubeflow/data/FashionMNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"/home/jovyan/mlops-kubeflow/data/FashionMNIST\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    for (x_train, y_train) in train_dataloader:\n",
    "        print(\"Shape of X [N, C, H, W]: \", x_train.shape)\n",
    "        print(\"Shape of y: \", y_train.shape, y_train.dtype)\n",
    "        break\n",
    "\n",
    "#     plt.figure(figsize=(10, 1))\n",
    "#     for i in range(10):\n",
    "#         plt.subplot(1, 10, i + 1)\n",
    "#         plt.imshow(x_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "#         plt.title(\"class: \" + str(y_train[i].item()))\n",
    "#         plt.axis(\"off\")\n",
    "\n",
    "    class NeuralNetwork(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            output = F.log_softmax(logits, dim=1)\n",
    "            return output\n",
    "\n",
    "    model = NeuralNetwork().to(device)\n",
    "    print(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    def train(dataloader, model, loss_fn, optimizer):\n",
    "        size = len(dataloader.dataset)\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 예측 오류 계산\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # 역전파\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 500 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                # 텐서보드에 Train Loss / per epoch 로그 기록 \n",
    "                writer.add_scalar('Train/Loss', loss, t+1)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "\n",
    "    def test(dataloader, model, loss_fn):\n",
    "        size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        test_accuracy = 100. * correct \n",
    "        # 텐서보드에 Test 로그 기록\n",
    "        writer.add_scalar('Test/Loss', test_loss, t+1)\n",
    "        writer.add_scalar('Test/Accuracy', test_accuracy, t+1)\n",
    "        writer.flush()\n",
    "        print(f\"Test Result: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    date_folder = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # 분기설정 \n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        log_dir = \"/home/jovyan/log/fit/\" + date_folder\n",
    "    else:\n",
    "        log_dir = \"/home/jovyan/job/log/fit/\" + date_folder  \n",
    "        \n",
    "    print(f\"tensorboard log dir : {log_dir}\")\n",
    "   \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    epochs = 3\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455ebaf0-3780-469e-bd53-d9b870629db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairing.config.set_builder(\n",
    "    'append',\n",
    "    image_name='fairing-job',\n",
    "    registry=DOCKER_REGISTRY,\n",
    "    base_image='www.dolearn.io:30003/base/fairing-base:0.0.2')\n",
    "\n",
    "fairing.config.set_deployer('job',\n",
    "                            cleanup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94c09db-7423-46b1-9b2e-ef0124b5bbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 220123 12:38:06 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.function.FunctionPreProcessor object at 0x7f951c9a3ac8>\n",
      "[I 220123 12:38:06 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f95607899b0>\n",
      "[I 220123 12:38:06 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f9539f496d8>\n",
      "[W 220123 12:38:06 append:52] Building image using Append builder...\n",
      "[I 220123 12:38:06 base:112] Creating docker context: /tmp/fairing_context_u2gxe6sg\n",
      "[W 220123 12:38:06 base:99] /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "[I 220123 12:38:06 docker_creds_:234] Loading Docker credentials for repository 'www.dolearn.io:30003/base/fairing-base:0.0.2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote train_with_fairing\n",
      "==========================================================\n",
      "Image name :  www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D\n",
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 220123 12:38:07 append:56] Image successfully built in 0.7979426719248295s.\n",
      "[W 220123 12:38:07 append:98] Pushing image www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D...\n",
      "[I 220123 12:38:07 docker_creds_:234] Loading Docker credentials for repository 'www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D'\n",
      "[W 220123 12:38:07 append:85] Uploading www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Image name :  www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D\n",
      "==========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 220123 12:38:07 docker_session_:280] Layer sha256:641afa4edc436e3fd3efd40433f1ad0c55b48af949680cd2359de51e3c439699 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:a4dd3c805ec24b016ac8a3869add24541829736c312b65bd49d3b2af7501f897 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:4bf23ae646f0b9d8e07bf427c69c82f208bb57a8b297507d9b8b6fa23b725711 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:3caed8c8884bf3a0cd5255f42fec14c219153bcdf294c81cb2e0599298c8a8df exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:29d136a889d232058c476b5637c18cbfca74c586634cbee07fe71fa540c7b211 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:063a4ff324e290814ea5bf23d5f8de5cca1a734782c4a187132ab3364b44a985 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:f5098a9bf4490bccac9085b1bf9c54baf3015333c40fb6685889a9785b7388ee exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:e80c964ece6a3edf0db1cfc72ae0e6f0699fb776bbfcc92b708fbb945b0b9547 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:9151e6e2942f84adfd723f3117577c80e9bd90fab642b2190a5e501fe01f534a exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:f22ccc0b8772d8e1bcb40f137b373686bc27427a70c0e41dd22b38016e09e7e0 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:208b1b1d503e89fb2452c622d99f8a69b643819c098688dd89a4bce51d843f7d exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:7ada0795a7988a0d48120cfe85bc57dba3bdd225474db83b4e5565b4af8dd0a9 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:191b6069f9932358899ffcc3f45c41a0f5f2731b948236a6553484caaf989794 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:c2d4f0d01c44ad399bb8b2efb64862646f347fa427ec85f193c57c8ef1127acb exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:40c455d0dacc33a87519926f4749deef90e15bca99118d8bf7d8cf78588f7f9b exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:7a12503ba844465b2c5aea7ebf60dd5057c7fcece51ea15e5f7f02ed1ae08d12 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:f571d568b0961b0954a50f361ad842acab3b6e4b21a27430e172a1f0d5aca5db exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:e1b8f4d5dcdfb4ac873d37d3a643cba6a55f2b325cfe0115aaba32946e896e0a exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:3cf8fb62ba5ffb221a2edb2208741346eb4d2d99a174138e4afbb69ce1fd9966 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:0269b6883f78a00bb29875d37fe3d838dbbe61cadf0108145fff2be316364f74 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:8bcf82863cb9582a24dc32cd3ddf560ff2f84df88694be072758159b94b70bd3 exists, skipping\n",
      "[I 220123 12:38:08 docker_session_:280] Layer sha256:02842a89d653002ea6c32f5573a9cec312ace226dae5eea21bc68782f4e2f627 exists, skipping\n",
      "[I 220123 12:38:09 docker_session_:284] Layer sha256:994401b2d1963712b03332c99d8f449117fb0d6ec3232a32a1d37c02ad24db03 pushed.\n",
      "[I 220123 12:38:09 docker_session_:334] Finished upload of: www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D\n",
      "[W 220123 12:38:09 append:103] Pushed image www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D in 2.03342267498374s.\n",
      "[W 220123 12:38:09 job:101] The job fairing-job-ffdq8 launched.\n",
      "[W 220123 12:38:09 manager:298] Waiting for fairing-job-ffdq8-g2w58 to start...\n",
      "[W 220123 12:38:09 manager:298] Waiting for fairing-job-ffdq8-g2w58 to start...\n",
      "[W 220123 12:38:09 manager:298] Waiting for fairing-job-ffdq8-g2w58 to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Building image www.dolearn.io:30003/kade-kubeflow/fairing-job:D1EDD38D done.\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 220123 12:38:10 manager:298] Waiting for fairing-job-ffdq8-g2w58 to start...\n",
      "[I 220123 12:38:12 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8%\n",
      "1.6%\n",
      "2.4%\n",
      "3.2%\n",
      "4.0%\n",
      "4.8%\n",
      "5.6%\n",
      "6.3%\n",
      "7.1%\n",
      "7.9%\n",
      "8.7%\n",
      "9.5%\n",
      "10.3%\n",
      "10.9%\n",
      "11.6%\n",
      "12.2%\n",
      "12.9%\n",
      "13.6%\n",
      "14.2%\n",
      "14.9%\n",
      "15.5%\n",
      "16.2%\n",
      "16.9%\n",
      "17.5%\n",
      "18.2%\n",
      "18.9%\n",
      "19.5%\n",
      "20.2%\n",
      "20.8%\n",
      "21.5%\n",
      "22.2%\n",
      "22.8%\n",
      "23.5%\n",
      "24.1%\n",
      "24.8%\n",
      "25.5%\n",
      "26.1%\n",
      "26.8%\n",
      "27.5%\n",
      "28.1%\n",
      "28.8%\n",
      "29.4%\n",
      "30.1%\n",
      "30.8%\n",
      "31.4%\n",
      "32.1%\n",
      "32.7%\n",
      "33.4%\n",
      "34.1%\n",
      "34.7%\n",
      "35.4%\n",
      "36.1%\n",
      "36.7%\n",
      "37.4%\n",
      "38.0%\n",
      "38.7%\n",
      "39.4%\n",
      "40.0%\n",
      "40.7%\n",
      "41.3%\n",
      "42.0%\n",
      "42.7%\n",
      "43.3%\n",
      "44.0%\n",
      "44.7%\n",
      "45.3%\n",
      "46.0%\n",
      "46.6%\n",
      "47.3%\n",
      "48.0%\n",
      "48.6%\n",
      "49.3%\n",
      "49.9%\n",
      "50.6%\n",
      "51.3%\n",
      "51.9%\n",
      "52.6%\n",
      "53.3%\n",
      "53.9%\n",
      "54.6%\n",
      "55.2%\n",
      "55.9%\n",
      "56.6%\n",
      "57.2%\n",
      "57.9%\n",
      "58.5%\n",
      "59.2%\n",
      "59.9%\n",
      "60.5%\n",
      "61.2%\n",
      "61.8%\n",
      "62.5%\n",
      "63.2%\n",
      "63.8%\n",
      "64.5%\n",
      "65.2%\n",
      "65.8%\n",
      "66.5%\n",
      "67.1%\n",
      "67.8%\n",
      "68.5%\n",
      "69.1%\n",
      "69.8%\n",
      "70.4%\n",
      "71.1%\n",
      "71.8%\n",
      "72.4%\n",
      "73.1%\n",
      "73.8%\n",
      "74.4%\n",
      "75.1%\n",
      "75.7%\n",
      "76.4%\n",
      "77.1%\n",
      "77.7%\n",
      "78.4%\n",
      "79.0%\n",
      "79.7%\n",
      "80.4%\n",
      "81.0%\n",
      "81.7%\n",
      "82.4%\n",
      "83.0%\n",
      "83.7%\n",
      "84.3%\n",
      "85.0%\n",
      "85.7%\n",
      "86.3%\n",
      "87.0%\n",
      "87.6%\n",
      "88.3%\n",
      "89.0%\n",
      "89.6%\n",
      "90.3%\n",
      "91.0%\n",
      "91.6%\n",
      "92.3%\n",
      "92.9%\n",
      "93.6%\n",
      "94.3%\n",
      "94.9%\n",
      "95.6%\n",
      "96.2%\n",
      "96.9%\n",
      "97.6%\n",
      "98.2%\n",
      "98.9%\n",
      "99.5%\n",
      "100.0%\n",
      "100.6%\n",
      "4.7%\n",
      "9.5%\n",
      "13.5%\n",
      "17.5%\n",
      "21.4%\n",
      "25.4%\n",
      "29.3%\n",
      "33.3%\n",
      "37.2%\n",
      "41.2%\n",
      "45.1%\n",
      "49.1%\n",
      "53.0%\n",
      "57.0%\n",
      "60.9%\n",
      "64.9%\n",
      "68.8%\n",
      "72.8%\n",
      "76.7%\n",
      "80.7%\n",
      "84.6%\n",
      "88.6%\n",
      "92.6%\n",
      "96.5%\n",
      "100.0%\n",
      "119.3%\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "Using cpu device\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /home/jovyan/mlops-kubeflow/data/FashionMNIST/FashionMNIST/raw\n",
      "\n",
      "Shape of X [N, C, H, W]:  torch.Size([32, 1, 28, 28])\n",
      "Shape of y:  torch.Size([32]) torch.int64\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "tensorboard log dir : /home/jovyan/job/log/fit/20220123-123911\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302831  [    0/60000]\n",
      "loss: 2.275911  [16000/60000]\n",
      "loss: 2.240531  [32000/60000]\n",
      "loss: 2.213825  [48000/60000]\n",
      "Test Result:\n",
      " Accuracy: 43.8%, Avg loss: 2.125480\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.164553  [    0/60000]\n",
      "loss: 2.032569  [16000/60000]\n",
      "loss: 1.902235  [32000/60000]\n",
      "loss: 1.794592  [48000/60000]\n",
      "Test Result:\n",
      " Accuracy: 50.3%, Avg loss: 1.758448\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.665094  [    0/60000]\n",
      "loss: 1.843717  [16000/60000]\n",
      "loss: 1.607679  [32000/60000]\n",
      "loss: 1.431297  [48000/60000]\n",
      "Test Result:\n",
      " Accuracy: 53.9%, Avg loss: 1.490360\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('remote train_with_fairing')\n",
    "    remote_train = fairing.config.fn(train_with_fairing)\n",
    "    remote_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9606a-03d4-4675-9298-81fca416c7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
